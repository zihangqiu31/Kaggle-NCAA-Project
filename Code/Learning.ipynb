{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib import pyplot\n",
    "import sklearn.metrics as metrics\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'Season', 'T1', 'T2','ScoreDif',\n",
    "       'T1MFAc', 'T1MFAc3', 'T1MSAc', 'T1MRC', 'T1MAst', 'T1MStl', 'T1MBlk',\n",
    "       'T1MScoreDif', 'T1VFAc', 'T1VFAc3', 'T1VSAc', 'T1VRC', 'T1Seed',\n",
    "       'T2MFAc','T2MFAc3', 'T2MSAc', 'T2MRC', 'T2MAst', 'T2MStl', 'T2MBlk',\n",
    "       'T2MScoreDif', 'T2VFAc', 'T2VFAc3', 'T2VSAc', 'T2VRC', \n",
    "       'T2Seed', 'SeedDif'\n",
    "\n",
    "'''\n",
    "games = np.genfromtxt('processed_np.csv', delimiter=',')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "train = (games[:,0]<2015)\n",
    "X_train,X_test = games[train,4:], games[~train,4:]\n",
    "y_train,y_test = games[train,3],games[~train,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(alg,test_input,test_result):\n",
    "    preds = alg.predict(test_input)\n",
    "    # to prob\n",
    "    test_result[test_result>=0] = 1\n",
    "    test_result[test_result<0] = 0\n",
    "    loss = -np.mean(test_result*np.log(preds)+(1-test_result)*np.log(1-preds))\n",
    "    print(\"Log_Loss : %f\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(alg,test_input,test_result):\n",
    "    preds = alg.predict(test_input)\n",
    "    error = np.sqrt(np.mean((test_result*preds)**2))\n",
    "    print(\"RMSE : %f\" % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg,X,y,useCV= True,cv_folds=5, early_stopping_rounds=50):\n",
    "    if useCV:\n",
    "        xgb_param = alg.get_params()\n",
    "        xgtrain = xgb.DMatrix(X,y)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                          metrics='rmse', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    alg.fit(X,y,eval_metric='rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime : 0.081017\n",
      "RMSE : 0.513872\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train,label = y_train)\n",
    "dtest = xgb.DMatrix(X_test,label = y_test)\n",
    "model = xgb.XGBRegressor(colsample_bytree=0.9,\n",
    "                         gamma=0,\n",
    "                         learning_rate=0.001,\n",
    "                         max_depth=2,\n",
    "                         min_child_weight=1,\n",
    "                         n_estimators=20,  \n",
    "                         reg_alpha=1e-05,\n",
    "                         reg_lambda=0,\n",
    "                         subsample=0.7,\n",
    "                         seed=42)\n",
    "t = time.time()\n",
    "modelfit(model,X_train,y_train,useCV= True,cv_folds=5, early_stopping_rounds=50)\n",
    "#model.fit(X_train,y_train)\n",
    "print(\"runtime : %f\" % (time.time()-t))\n",
    "rmse(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.Series(model.feature_importances_).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-12.633021974907601, {'max_depth': 2, 'min_child_weight': 1})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuning tree param\n",
    "# try different depth and weight value to find optimal \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_test = {'max_depth':range(1,5),\n",
    "             'min_child_weight':range(1,5)}\n",
    "gsearch = GridSearchCV(estimator = model,\n",
    "                      param_grid = param_test, scoring='neg_root_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch.fit(X_train,y_train)\n",
    "gsearch.best_score_,gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-12.633021974907601, {'gamma': 0.0})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {'gamma':[i/10.0 for i in range(0,5)]}\n",
    "gsearch = GridSearchCV(estimator = model,\n",
    "                      param_grid = param_test2, scoring='neg_root_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch.fit(X_train,y_train)\n",
    "gsearch.best_score_,gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-12.573635988889842, {'colsample_bytree': 0.9, 'n_estimators': 20})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "              'n_estimators': range(16,25)}\n",
    "gsearch = GridSearchCV(estimator = model,\n",
    "                      param_grid = param_test3, scoring='neg_root_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch.fit(X_train,y_train)\n",
    "gsearch.best_score_,gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-12.618871043282931, {'reg_alpha': 1e-05, 'reg_lambda': 0})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100],\n",
    "              'reg_lambda': [0, 0.001, 0.005, 0.01, 0.05]}\n",
    "gsearch = GridSearchCV(estimator = model,\n",
    "                      param_grid = param_test4, scoring='neg_root_mean_squared_error',n_jobs=4,iid=False, cv=5)\n",
    "gsearch.fit(X_train,y_train)\n",
    "gsearch.best_score_,gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output submission\n",
    "#read and predict\n",
    "sub = np.genfromtxt('submission_input.csv', delimiter=',')\n",
    "sub_preds = model.predict(sub[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write and to_prob\n",
    "submission = pd.read_csv('C:\\\\Users\\\\luciu\\\\Box Sync\\\\ncaa-march-madness-2020\\\\data\\\\MSampleSubmissionStage1_2020.csv')\n",
    "mu, std = norm.fit(sub_preds)\n",
    "sub_prob = norm.cdf(sub_preds,mu,std)\n",
    "submission['Pred'] = sub_prob\n",
    "submission.to_csv(r'C:\\\\Users\\\\luciu\\\\Box Sync\\\\ncaa-march-madness-2020\\\\code\\submission1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
